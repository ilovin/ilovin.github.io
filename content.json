{"meta":{"title":"Scott's Notes","subtitle":null,"description":null,"author":"Scott","url":"http://ilovin.me","root":"/"},"pages":[{"title":"categories","date":"un33fin33","updated":"un33fin33","comments":false,"path":"categories/index.html","permalink":"http://ilovin.me/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"un33fin33","updated":"un33fin33","comments":false,"path":"tags/index.html","permalink":"http://ilovin.me/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"互联网中的人来人往","slug":"person-in-the-network","date":"un66fin66","updated":"un66fin66","comments":true,"path":"2021-01-23/person-in-the-network/","link":"","permalink":"http://ilovin.me/2021-01-23/person-in-the-network/","excerpt":"","text":"互联网中人来人往再正常不过，而在创业公司这种氛围就显得更加微妙了一些。 大家为什么要来一家创业公司?对于一线民工来说，谁又何尝不是冲着成就一番事业而来的呢？新技术，新方向，制造一些前人从没有实现过的产品，挑战行业龙头，把现有的产品再往上推一个层次，这何尝不让人兴奋。从这个角度来说创业的人其实是同一类人，因此除了同事伙伴关系以外，用战友来描述这些同路人是不能更恰当的了。 然而合作有多紧密，分开时就有多痛苦。随着一个又一个伙伴因为这样或者那样的原因逐渐离去，其中感情又怎能是一句遗憾就能概括。如果最后产品成功了，而当初的伙伴不在身边了，那, 还算成功吗？ 做一款成功的产品太重要了，不仅是为了实现自我价值，从某种程度上来说, 一款成功的产品可以让人越聚越多，反之就是种种不如意。结果和过程二者同样重要！但世事却偏偏不如人心意。","categories":[],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"http://ilovin.me/tags/%E6%9D%82%E8%B0%88/"},{"name":"行业","slug":"行业","permalink":"http://ilovin.me/tags/%E8%A1%8C%E4%B8%9A/"},{"name":"megvii/face++","slug":"megvii-face","permalink":"http://ilovin.me/tags/megvii-face/"}]},{"title":"为什么旷视要做指纹","slug":"why-megvii-doing-fingerprint","date":"un22fin22","updated":"un22fin22","comments":true,"path":"2020-12-01/why-megvii-doing-fingerprint/","link":"","permalink":"http://ilovin.me/2020-12-01/why-megvii-doing-fingerprint/","excerpt":"Background2020年屏下指纹已经成为高端乃至中端机型的标准配置. 从技术上分类, 市面上的技术主要分为光学方案和超声波方案. 其中超声波方案主要由高通领衔开发并主要应用于三星的高端机型上. 而光学方案占据了绝大多数的市场份额, 汇顶是其中绝对的领头羊. 由于oppo和思立微之间的合作伙伴关系, 以及思立微较早入局的先发优势, 其在市场中也享有一定的份额. 另一方面, 旷视作为一个已经存在9年的人工智能”初创企业”, 在经历了几年人工智能做什么的迷茫过后, 凭借之前人脸识别技术在手机厂获得的良好口碑, 一个偶然的机会, 获得了屏下指纹供应链的入场门票. 而这也被旷视视为从单纯的卖SDK切换到AIOT软硬一体赛道的重要一步. 那么旷视为什么要转型，步入到新赛道又遇到了什么困难。","text":"Background2020年屏下指纹已经成为高端乃至中端机型的标准配置. 从技术上分类, 市面上的技术主要分为光学方案和超声波方案. 其中超声波方案主要由高通领衔开发并主要应用于三星的高端机型上. 而光学方案占据了绝大多数的市场份额, 汇顶是其中绝对的领头羊. 由于oppo和思立微之间的合作伙伴关系, 以及思立微较早入局的先发优势, 其在市场中也享有一定的份额. 另一方面, 旷视作为一个已经存在9年的人工智能”初创企业”, 在经历了几年人工智能做什么的迷茫过后, 凭借之前人脸识别技术在手机厂获得的良好口碑, 一个偶然的机会, 获得了屏下指纹供应链的入场门票. 而这也被旷视视为从单纯的卖SDK切换到AIOT软硬一体赛道的重要一步. 那么旷视为什么要转型，步入到新赛道又遇到了什么困难。 Introduction一个全新的赛道, 给旷视带来了机遇与挑战. 切换到AIOT领域意味着旷视的商业模式从白菜价售卖SDK转变到以合理价格按件付费上来, 其中的市场规模不可同日而语. 但与此同时这也给指纹团队带来挑战. 从技术层面上来说, 旷视之前在安防云服务等业务上积累的经验, 总体上可以概况为一个图片或者视频流在经过一个网络后得到一个结果, 旷视要做的就是使得这个结果的正确率尽量的高并且保证服务器端GPU上训练的模型可以在服务器端CPU或者手机端得到相同的结果. 在业界这两个事情也被叫做”nn一把梭”和”对分”, —to be continue Next超薄还是光学屏下指纹大面积是不是未来, 现在的瓶颈在什么旷视为何要转型，此次转型的关键是什么","categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://ilovin.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"杂谈","slug":"杂谈","permalink":"http://ilovin.me/tags/%E6%9D%82%E8%B0%88/"},{"name":"行业","slug":"行业","permalink":"http://ilovin.me/tags/%E8%A1%8C%E4%B8%9A/"},{"name":"指纹/fingerprint","slug":"指纹-fingerprint","permalink":"http://ilovin.me/tags/%E6%8C%87%E7%BA%B9-fingerprint/"},{"name":"megvii/face++","slug":"megvii-face","permalink":"http://ilovin.me/tags/megvii-face/"}]},{"title":"TPS变换","slug":"tps-transformation","date":"un00fin00","updated":"un00fin00","comments":true,"path":"2019-06-09/tps-transformation/","link":"","permalink":"http://ilovin.me/2019-06-09/tps-transformation/","excerpt":"先放两个原理链接:Thin plate spline wikipedia link;ieee link. 具体的公式可以看 《ASTER: An and Attentional Scene and Text Recognizer and with Flexible and Rectification》github: pytorch &amp; numpy implement","text":"先放两个原理链接:Thin plate spline wikipedia link;ieee link. 具体的公式可以看 《ASTER: An and Attentional Scene and Text Recognizer and with Flexible and Rectification》github: pytorch &amp; numpy implement numpy是按照论文里实现的, pytorch的实现来自实验室, 应该有所不同, 但结果应该是一致的. 简单说一下TPS的使用感觉, 相比于透视变换要灵活很多, 但是过于灵活, 如果你的点对误差很大的话, 那么局部畸变会很严重.","categories":[],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://ilovin.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://ilovin.me/tags/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"}]},{"title":"fblualib在ubuntu 16.04上的安装","slug":"fblualib-install-16-04","date":"un55fin55","updated":"un00fin00","comments":true,"path":"2018-05-11/fblualib-install-16-04/","link":"","permalink":"http://ilovin.me/2018-05-11/fblualib-install-16-04/","excerpt":"最近需要复现一下CRNN的结果，因为自己实现的版本点数不够高，所以需要跑一下人家的代码。一共有两个依赖，一个是TORCH，这个好装，另一个是fblualib，这个项目已经停止维护了，真的是跳了无数个坑，这里做一个记录。最后也只能跑inference不能train BTW. 但是对于其他跳坑的人可能也是有帮助的.","text":"最近需要复现一下CRNN的结果，因为自己实现的版本点数不够高，所以需要跑一下人家的代码。一共有两个依赖，一个是TORCH，这个好装，另一个是fblualib，这个项目已经停止维护了，真的是跳了无数个坑，这里做一个记录。最后也只能跑inference不能train BTW. 但是对于其他跳坑的人可能也是有帮助的. 概览 torch cudnn.torch googletest folly mstch zstd googletest wangle fbthrift thpp fblualib CRNN 各种报错的解决办法 概览首先是需要安装的包fblualib,folly,mstch,zstd,wangle,thpp,fbthrift其次：system：ubuntu 16.04，相比来说14.04应该更好装python:2.7，之前试了python3，但是在import frontend的时候遇到了一些问题，没有解决好，就放弃了，其实是有希望的。 torchcommit 0219027e6c4644a0ba5c5bf137c989a0a8c9e01b cudnn.torch1git clone https:&#x2F;&#x2F;github.com&#x2F;soumith&#x2F;cudnn.torch googletest1234567wget https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;googletest&#x2F;archive&#x2F;release-1.8.0.tar.gz &amp;&amp; \\tar zxf release-1.8.0.tar.gz &amp;&amp; \\rm -f release-1.8.0.tar.gz &amp;&amp; \\cd googletest-release-1.8.0 &amp;&amp; \\cmake configure . &amp;&amp; \\make &amp;&amp; \\make install follycommit ID:5817bad依赖： 123456789101112131415161718192021sudo apt-get install \\ g++ \\ cmake \\ libboost-all-dev \\ libevent-dev \\ libdouble-conversion-dev \\ libgoogle-glog-dev \\ libgflags-dev \\ libiberty-dev \\ liblz4-dev \\ liblzma-dev \\ libsnappy-dev \\ make \\ zlib1g-dev \\ binutils-dev \\ libjemalloc-dev \\ libssl-dev \\ pkg-config libunwind8-dev \\ libelf-dev \\ libdwarf-dev 1234567git clone https:&#x2F;&#x2F;github.com&#x2F;facebook&#x2F;folly&#x2F;cd folly&#x2F;follyautoreconf -ivf.&#x2F;configure &amp;&amp;make &amp;&amp;sudo make install &amp;&amp;sudo ldconfig &amp;&amp; mstchcommit ID:0fde1cf 1234567git clone https:&#x2F;&#x2F;github.com&#x2F;no1msd&#x2F;mstchcd mstchmkdir buildcd buildcmake ..make -j 4sudo make install zstdcommit ID:87125c2 dev branch 123git clone https:&#x2F;&#x2F;github.com&#x2F;facebook&#x2F;zstdcd zstdsudo make install googletest12git clone https:&#x2F;&#x2F;github.com&#x2F;google&#x2F;googletestcmake make install wanglecommit ID:`31fbaba 12345git clone https:&#x2F;&#x2F;github.com&#x2F;facebook&#x2F;wanglecmake .makectestsudo make install fbthriftcommit ID:94a399a更改的部分 123456789101112131415diff --git a&#x2F;CMakeLists.txt b&#x2F;CMakeLists.txtindex 51271e3..7a15eae 100644--- a&#x2F;CMakeLists.txt+++ b&#x2F;CMakeLists.txt@@ -8,6 +8,9 @@ set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY $&#123;CMAKE_BINARY_DIR&#125;&#x2F;lib) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY $&#123;CMAKE_BINARY_DIR&#125;&#x2F;lib) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY $&#123;CMAKE_BINARY_DIR&#125;&#x2F;bin)+set(CMAKE_CXX_FLAGS &quot;-fPIC&quot;)+set(CMAKE_C_FLAGS &quot;-fPIC&quot;)+ set(TEMPLATES_INSTALL_DIR include&#x2F;thrift&#x2F;templates CACHE STRING &quot;The subdirectory where compiler template files should be installed&quot;) set(BIN_INSTALL_DIR bin CACHE STRING主要为了解决python包 thrift-compiler无法生成的问题 123cd buildcmake ..make -j 32 thppcommit ID:0a4c745 123git clone https:&#x2F;&#x2F;github.com&#x2F;facebook&#x2F;thppcd thpp&#x2F;thpp.&#x2F;build.sh 更改的部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051diff --git a&#x2F;thpp&#x2F;CMakeLists.txt b&#x2F;thpp&#x2F;CMakeLists.txtindex 4ae3683..603702b 100644--- a&#x2F;thpp&#x2F;CMakeLists.txt+++ b&#x2F;thpp&#x2F;CMakeLists.txt@@ -42,7 +42,7 @@ ELSE() ADD_DEFINITIONS(-DNO_THRIFT) ENDIF()-SET(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std&#x3D;gnu++11&quot;)+SET(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std&#x3D;gnu++14&quot;) SET(src Storage.cpp------------------------------------------------------ diff --git a&#x2F;thpp&#x2F;build.sh b&#x2F;thpp&#x2F;build.sh index 79af5d9..7c807e7 100755 --- a&#x2F;thpp&#x2F;build.sh +++ b&#x2F;thpp&#x2F;build.sh @@ -52,4 +52,4 @@ make ctest # Install -make install +sudo make install------------------------------------------------------diff --git a&#x2F;thpp&#x2F;detail&#x2F;TensorGeneric.h b&#x2F;thpp&#x2F;detail&#x2F;TensorGeneric.hindex a8837f6..6b67c72 100644--- a&#x2F;thpp&#x2F;detail&#x2F;TensorGeneric.h+++ b&#x2F;thpp&#x2F;detail&#x2F;TensorGeneric.h@@ -188,17 +188,17 @@ template &lt;&gt; struct TensorOps&lt;Tensor&lt;real&gt;&gt; &#123; &#125; static void _max(THTensor* values, THLongTensor* indices, THTensor* t, int dim) &#123;- return THTensor_(max)(values, indices, t, dim);+ return THTensor_(max)(values, indices, t, dim, 1); &#125; static void _min(THTensor* values, THLongTensor* indices, THTensor* t, int dim) &#123;- return THTensor_(min)(values, indices, t, dim);+ return THTensor_(min)(values, indices, t, dim, 1); &#125; static void _sum(THTensor* r, THTensor* t, int dim) &#123;- return THTensor_(sum)(r, t, dim);+ return THTensor_(sum)(r, t, dim, 1); &#125; static void _prod(THTensor* r, THTensor* t, int dim) &#123;- return THTensor_(prod)(r, t, dim);+ return THTensor_(prod)(r, t, dim, 1); &#125; static void _cumsum(THTensor* r, THTensor* t, int dim) &#123; return THTensor_(cumsum)(r, t, dim); fblualibcommit ID:4812779更改的部分，这个改的太多了 1234567891011modified: fblualib&#x2F;build.shmodified: fblualib&#x2F;ffivector&#x2F;CMakeLists.txtmodified: fblualib&#x2F;ffivector&#x2F;FFIVector.cppmodified: fblualib&#x2F;mattorch&#x2F;CMakeLists.txtmodified: fblualib&#x2F;python&#x2F;CMakeLists.txtmodified: fblualib&#x2F;thrift&#x2F;ChunkedCompression.hmodified: fblualib&#x2F;thrift&#x2F;Encoding.hmodified: fblualib&#x2F;thrift&#x2F;LuaObject.hmodified: fblualib&#x2F;thrift&#x2F;LuaSerialization.cppmodified: fblualib&#x2F;torch&#x2F;CMakeLists.txtmodified: fblualib&#x2F;util&#x2F;Reactor.cpp CRNNptr的问题 各种报错的解决办法1234567Could not find a package configuration file provided by &quot;Torch&quot; with any of the following names: TorchConfig.cmake torch-config.cmakeexport CMAKE_PREFIX_PATH&#x3D;&#x2F;path&#x2F;to&#x2F;torch","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"深度学习","slug":"技术杂谈/深度学习","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"http://ilovin.me/tags/ubuntu/"},{"name":"install","slug":"install","permalink":"http://ilovin.me/tags/install/"}]},{"title":"各大深度学习顶会举办地点","slug":"conference-location","date":"un22fin22","updated":"un22fin22","comments":true,"path":"2018-01-02/conference-location/","link":"","permalink":"http://ilovin.me/2018-01-02/conference-location/","excerpt":"最近在写论文，用Google Scholar，但是搜出来的cite好多都不全，尤其是各种会议的举办地，简直找到吐。还是总结一下，以后好找。主要收录的会议有CVPR，ICCV，ECCV，ICPR，ICML","text":"最近在写论文，用Google Scholar，但是搜出来的cite好多都不全，尤其是各种会议的举办地，简直找到吐。还是总结一下，以后好找。主要收录的会议有CVPR，ICCV，ECCV，ICPR，ICML CVPR ICCV ECCV ICPR ICML CVPRIEEE Year Address 2021 Toronto 2020 Seattle, WA, USA 2019 Long Beach, CA, USA 2018 Salt Lake City, UT, USA 2017 Honolulu, HI, USA 2016 Las Vegas, NV, USA 2015 Boston, MA, USA 2014 Columbus, OH, USA 2013 Portland, OR, USA 2012 Providence, RI, USA 2011 Colorado Springs, CO, USA 2010 San Francisco, CA, USA 2009 Miami, FL, USA 2008 Anchorage, AL, USA 2007 Minneapolis, MN, USA 2006 New York City, NY, USA 2005 San Diego, CA, USA 2004 Washington, DC, USA 2003 Madison, WI, USA 2002 NULL 2001 Kauai, HI, USA 2000 Hilton Head, SC, USA ICCVIEEE Year Address 2019 Seoul, Korea 2017 Venice, Italy 2015 Santiago, Chile 2013 Sydney, Australia 2011 Barcelona, Spain 2009 Kyoto, Japan 2007 Rio de Janeiro, Brazil 2005 Beijing, China 2003 Nice, France 2001 Vancouver, Canada 1999 Kerkyra, Greece 1998 Bombay, India 1995 Boston, U.S.A 1993 Berlin, Germany 1990 Osaka, Japan 1988 Tampa, U.S.A 1987 London, United Kingdom ECCVIEEE Year Address 2020 Edinburgh, Scotland 2018 Munich, German 2016 Amsterdam, Netherlands 2014 Zurich, Zürich 2012 Florence, Italy 2010 Hersonissos, Greece 2008 Marseille, France 2006 Graz, Austrian 2004 Prague, Czech Republic 2002 Copenhagen, Denmark 2000 Dublin, Ireland 1998 Freiburg, Germany 1996 Cambridge, England 1994 Stockholm, Sweden 1992 Santa Margherita Ligure, Italy 1990 Antibes, France ICPRIEEE Conference Year Address 21st ICPR 2012 Tsukuba Science City, Japan 20th ICPR 2010 Istanbul, Turkey 19th ICPR 2008 Tampa, USA 18th ICPR 2006 Hong Kong, China 17th ICPR 2004 Cambridge, United Kingdom 16th ICPR 2002 Quebec City, Canada 15th ICPR 2000 Barcelona, Spain 14th ICPR 1998 Brisbane, Australia 13th ICPR 1996 Vienna, Austria 12th ICPR 1994 Jerusalem, Israel 11th ICPR 1992 The Hague, Netherlands 10th ICPR 1990 Atlantic City, USA 9th ICPR 1988 Rome, Italy 8th ICPR 1986 Paris, France 7th ICPR 1984 Montreal, Canada 6th ICPR 1982 Munich, Germany 5th ICPR 1980 Miami, USA 4th IJCPR 1978 Kyoto, Japan 3rd IJCPR 1976 San Diego, USA 2nd IJCPR 1974 Copenhagen, Denmark 1st IJCPR 1973 Washington, DC, USA ICMLIMLS Year Address 2018 Stockholm, Sweden 2017 Sydney, Australia 2016 New York City, United States 2015 Lille, France 2014 Beijing, China 2013 Atlanta, United States 2012 Edinburgh, Great Britain 2011 Bellevue, United States 2010 Haifa, Israel 2009 Montréal, Canada 2008 Helsinki, Finland 2007 Corvallis, Oregon, United States 2006 Pittsburgh, Pennsylvania, United States 2005 Bonn, Germany, EU 2004 Banff, Canada 2003 Washington, DC, United States 2002 Sydney, Australia 2001 Williamstown, Massachusetts, United States 2000 Stanford, California, United States 参考链接 CVPR &amp; ICCV &amp; ICPR CVPR &amp; ICCV &amp; ECCV ICML","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"深度学习","slug":"技术杂谈/深度学习","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[]},{"title":"TF实现attention时使用BeamSearchDecoder遇到的问题","slug":"beam-search-with-attention","date":"un66fin66","updated":"un22fin22","comments":true,"path":"2017-11-25/beam-search-with-attention/","link":"","permalink":"http://ilovin.me/2017-11-25/beam-search-with-attention/","excerpt":"","text":"训练和测试的时候不能在一张图上的问题。","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"深度学习","slug":"技术杂谈/深度学习","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"beam_search","slug":"beam-search","permalink":"http://ilovin.me/tags/beam-search/"},{"name":"attentiaon","slug":"attentiaon","permalink":"http://ilovin.me/tags/attentiaon/"}]},{"title":"Reading List","slug":"Reading-List","date":"un66fin66","updated":"un00fin00","comments":true,"path":"2017-07-29/Reading-List/","link":"","permalink":"http://ilovin.me/2017-07-29/Reading-List/","excerpt":"把最近读的和准备的文章做个小结，主要和图像分割、目标识别相关","text":"把最近读的和准备的文章做个小结，主要和图像分割、目标识别相关 场景文字分割 Baidu-WordSup: Exploiting Word Annotations for Character based Text Detection R2CNN: Rotational Region CNN for Orientation Robust Scene Text Detection Towards End-to-end Text Spotting with Convolutional Recurrent Neural Networks Megvii-EAST NLPR Deep Direct Regression for Multi-Oriented Scene Text Detection Multi-Oriented Text Detection with Fully Convolutional Networks CTPNgithub-link:caffe Synthetic Data for Text Localisation in Natural Imagesgithub-link 经典文章 FCNgithub: 自己实现的版本 Faster R-CNN YOLO9000 CTC warpCTC Gram-CTC","categories":[{"name":"Reading List","slug":"Reading-List","permalink":"http://ilovin.me/categories/Reading-List/"}],"tags":[{"name":"深度学习","slug":"深度学习","permalink":"http://ilovin.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"tensorflow LSTM+CTC/warpCTC使用详解","slug":"tensorflow-lstm-ctc-input-output","date":"un00fin00","updated":"un22fin22","comments":true,"path":"2017-04-23/tensorflow-lstm-ctc-input-output/","link":"","permalink":"http://ilovin.me/2017-04-23/tensorflow-lstm-ctc-input-output/","excerpt":"最近用tensorflow写了个OCR的程序，在实现的过程中，发现自己还是跳了不少坑，在这里做一个记录，便于以后回忆。主要的内容有lstm+ctc具体的输入输出，以及TF中的CTC和百度开源的warpCTC在具体使用中的区别。","text":"最近用tensorflow写了个OCR的程序，在实现的过程中，发现自己还是跳了不少坑，在这里做一个记录，便于以后回忆。主要的内容有lstm+ctc具体的输入输出，以及TF中的CTC和百度开源的warpCTC在具体使用中的区别。 正文输入输出因为我最后要最小化的目标函数就是ctc_loss，所以下面就从如何构造输入输出说起。 tf.nn.ctc_loss先从TF自带的tf.nn.ctc_loss说起，官方给的定义如下，因此我们需要做的就是将图片的label（需要OCR出的结果），图片，以及图片的长度转换为label，input，和sequence_length。 12345678ctc_loss( labels, inputs, sequence_length, preprocess_collapse_repeated&#x3D;False, ctc_merge_repeated&#x3D;True, time_major&#x3D;True) input: 输入（训练）数据，是一个三维float型的数据结构[max_time_step , batch_size , num_classes]，当修改time_major = False时，[batch_size,max_time_step,num_classes]。总体的数据流：image_batch-&gt;[batch_size,max_time_step,num_features]-&gt;lstm-&gt;[batch_size,max_time_step,cell.output_size]-&gt;reshape-&gt;[batch_size*max_time_step,num_hidden]-&gt;affine projection A*W+b-&gt;[batch_size*max_time_step,num_classes]-&gt;reshape-&gt;[batch_size,max_time_step,num_classes]-&gt;transpose-&gt;[max_time_step,batch_size,num_classes]下面详细解释一下，假如一张图片有如下shape:[60,160,3]，我们如果读取灰度图则shape=[60,160]，此时，我们将其一列作为feature，那么共有60个features，160个time_step，这时假设一个batch为64，那么我们此时获得到了一个[batch_size,max_time_step,num_features] = [64,160,60]的训练数据。 然后将该训练数据送入构建的lstm网络中，(需要注意的是dynamic_rnn的输入数据在一个batch内的长度是固定的，但是不同batch之间可以不同,我们需要给他一个sequence_length（长度为batch_size的向量）来记录本次batch数据的长度，对于OCR这个问题，sequence_length就是长度为64，而值为160的一维向量)得到形如[batch_size,max_time_step,cell.output_size]的输出，其中cell.output_size == num_hidden。 下面我们需要做一个线性变换将其送入ctc_loos中进行计算，lstm中不同time_step之间共享权值，所以我们只需定义W的结构为[num_hidden,num_classes]，b的结构为[num_classes]。而tf.matmul操作中，两个矩阵相乘阶数应当匹配，所以我们将上一步的输出reshape成[batch_size*max_time_step,num_hidden]（num_hidden为自己定义的lstm的unit个数）记为A，然后将其做一个线性变换，于是A*w+b得到形如[batch_size*max_time_step,num_classes]然后在reshape回来得到[batch_size,max_time_step,num_classes]最后由于ctc_loss的要求，我们再做一次转置，得到[max_time_step,batch_size,num_classes]形状的数据作为input labels: 标签序列由于OCR的结果是不定长的，所以label实际上是一个稀疏矩阵SparseTensor，其中： indices:二维int64的矩阵，代表非0的坐标点 values:二维tensor，代表indice位置的数据值 dense_shape:一维，代表稀疏矩阵的大小比如有两幅图，分别是123,和4567那么indecs = [[0,0],[0,1],[0,2],[1,0],[1,1],[1,2],[1,3]]values = [1,2,3,4,5,6,7]dense_shape = [2,4]代表dense tensor:12[[1,2,3,0] [4,5,6,7]] seq_len: 在input一节中已经讲过，一维数据，[time_step,…,time_step]长度为batch_size,值为time_step warpCTC对于warpCTC需要注意几点 输入格式：有四个输入，与标准CTC的三个输入不同 class_label问题，标准CTC的情况下，如果自己使用的数据有N中类别，分别是0~N-1,那么标准CTC会把默认的blank类别作为第N类，而warpCTC中0被用作了默认的blank标签 proprocess_collapse_repeated必须设为False， ctc_merge_repeated为True，这是默认值，无需过多注意，另一方面来说过来说，就是这个值不能被更改，warpCTC还不支持，详见这个链接 costs = warpctc_tensorflow.ctc(activations, flat_labels, label_lengths, input_lengths) to be continue…","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"深度学习","slug":"技术杂谈/深度学习","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"ctc","slug":"ctc","permalink":"http://ilovin.me/tags/ctc/"},{"name":"lstm","slug":"lstm","permalink":"http://ilovin.me/tags/lstm/"}]},{"title":"Python批量将多张图片拼接为PDF","slug":"stitch-img-to-pdf","date":"un22fin22","updated":"un33fin33","comments":true,"path":"2017-04-18/stitch-img-to-pdf/","link":"","permalink":"http://ilovin.me/2017-04-18/stitch-img-to-pdf/","excerpt":"最近碰到一个问题，想要把一个文件夹下的图片拼接起来生成一个PDF文件，并且该PDF文件每页都具有相同的A4大小。其实生成PDF这件事有许多方法可以办到，最简单可以用word或者acrobat，然而通过这些软件来生成PDF文件有些问题无法避免，一是样式无法自定义，二是不太好把它做成一个模块嵌入到其他需要使用的地方。于是就想能否自己来写，好在Python轮子多，简单搜索了一下，用ReportLab似乎可以达到自己的要求。","text":"最近碰到一个问题，想要把一个文件夹下的图片拼接起来生成一个PDF文件，并且该PDF文件每页都具有相同的A4大小。其实生成PDF这件事有许多方法可以办到，最简单可以用word或者acrobat，然而通过这些软件来生成PDF文件有些问题无法避免，一是样式无法自定义，二是不太好把它做成一个模块嵌入到其他需要使用的地方。于是就想能否自己来写，好在Python轮子多，简单搜索了一下，用ReportLab似乎可以达到自己的要求。 实现方法代码实现起来倒是不复杂，但是有一点需要注意，那就是用PIL打开一个图片的时候，当它是JPEG格式的时候，我发现它总是旋转过的，因此我们需要读取一下该图片的exif信息，将它转过来。 12345678910111213141516171819202122def rotate_img_to_proper(image): try: if hasattr(image, &#x27;_getexif&#x27;): # only present in JPEGs for orientation in PIL.ExifTags.TAGS.keys(): if PIL.ExifTags.TAGS[orientation] == &#x27;Orientation&#x27;: break e = image._getexif() # returns None if no EXIF data if e is not None: #log.info(&#x27;EXIF data found: %r&#x27;, e) exif = dict(e.items()) orientation = exif[orientation] # print(&#x27;found, &#x27;,orientation) if orientation == 3: image = image.transpose(Image.ROTATE_180) elif orientation == 6: image = image.transpose(Image.ROTATE_270) elif orientation == 8: image = image.rotate(90,expand=True) except: pass return image 随后我们就可以将图片保持长宽比地resize到A4页面中 12345678910111213141516171819202122# new a DocimgDoc = canvas.Canvas(output_file_name)#pagesize=letterimgDoc.setPageSize(A4)document_width,document_height = A4# fill each page with a imageimage_file = PIL.Image.open(image)image_file = rotate_img_to_proper(image_file)image_width,image_height = image_file.sizeif not(image_width&gt;0 and image_height&gt;0): raise Exceptionimage_aspect = image_height/float(image_width)#Determins the demensions of the image in the overviewprint_width = document_widthprint_height = document_width*image_aspectimgDoc.drawImage(ImageReader(image_file),document_width-print_width, document_height-print_height,width=print_width, height=print_height,preserveAspectRatio=True)#inform the reportlab we want a new pageimgDoc.showPage()imgDoc.save() 结果最终拼接出来的结果，是这个样子的完整的代码放在Github上，可以根据需求稍加更改使用","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"python","slug":"技术杂谈/python","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://ilovin.me/tags/python/"}]},{"title":"Disqus无法在Github Pages上加载的解决方法","slug":"disqus-load-problem","date":"un55fin55","updated":"un00fin00","comments":true,"path":"2017-04-07/disqus-load-problem/","link":"","permalink":"http://ilovin.me/2017-04-07/disqus-load-problem/","excerpt":"今天把评论系统迁移到disqus上后，发现有时能加载，有时不能加载，在手机端一直可以加载，百思不得其解，后来发现可以是以下几种原因，一个是disqus的http和https评论是分成两块的，所有会发现有的评论好像是消失了，还有一种可能是使用hexo的时候URL没有配置好。 解决方法知道问题的原因，接下来就简单了。对于前者，可以强制博客为https访问，我使用的是hexo的next主题，编辑next/layout/_layout.swig在head下添加如下代码 12345&lt;script type=&quot;text/javascript&quot;&gt; var host = &quot;your site&quot;; if ((host == window.location.host) &amp;&amp; (window.location.protocol != &quot;https:&quot;)) window.location.protocol = &quot;https&quot;;&lt;/script&gt; 对于第二种情况，在_config.yml重新配一下就好了","text":"今天把评论系统迁移到disqus上后，发现有时能加载，有时不能加载，在手机端一直可以加载，百思不得其解，后来发现可以是以下几种原因，一个是disqus的http和https评论是分成两块的，所有会发现有的评论好像是消失了，还有一种可能是使用hexo的时候URL没有配置好。 解决方法知道问题的原因，接下来就简单了。对于前者，可以强制博客为https访问，我使用的是hexo的next主题，编辑next/layout/_layout.swig在head下添加如下代码 12345&lt;script type=&quot;text/javascript&quot;&gt; var host = &quot;your site&quot;; if ((host == window.location.host) &amp;&amp; (window.location.protocol != &quot;https:&quot;)) window.location.protocol = &quot;https&quot;;&lt;/script&gt; 对于第二种情况，在_config.yml重新配一下就好了","categories":[{"name":"hexo","slug":"hexo","permalink":"http://ilovin.me/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://ilovin.me/tags/hexo/"}]},{"title":"tensorflow LSTM + CTC实现端到端OCR","slug":"tensorflow-lstm-ctc-ocr","date":"un44fin44","updated":"un00fin00","comments":true,"path":"2017-04-06/tensorflow-lstm-ctc-ocr/","link":"","permalink":"http://ilovin.me/2017-04-06/tensorflow-lstm-ctc-ocr/","excerpt":"最近在做OCR相关的东西，关于OCR真的是有悠久了历史了，最开始用tesseract然而效果总是不理想，其中字符分割真的是个博大精深的问题，那么多年那么多算法，然而应用到实际总是有诸多问题。比如说非等间距字体的分割，汉字的分割，有光照阴影的图片的字体分割等等，针对特定的问题，特定的算法能有不错的效果，但也仅限于特定问题，很难有一些通用的结果。于是看了Xlvector的博客之后，发现可以端到端来实现OCR，他是基于mxnet的，于是我想把它转到tensorflow这个框架来，顺便还能熟悉一下这个框架。本文主要介绍实现思路，更加细节的实现方法见另一篇。 正文生成数据利用captcha来生成验证码，具体生成验证码的代码请见这里，共生成4-6位包含数字和英文大小写的训练图片128000张和测试图片400张。命名规则就是num_label.png，生成的图片如下图","text":"最近在做OCR相关的东西，关于OCR真的是有悠久了历史了，最开始用tesseract然而效果总是不理想，其中字符分割真的是个博大精深的问题，那么多年那么多算法，然而应用到实际总是有诸多问题。比如说非等间距字体的分割，汉字的分割，有光照阴影的图片的字体分割等等，针对特定的问题，特定的算法能有不错的效果，但也仅限于特定问题，很难有一些通用的结果。于是看了Xlvector的博客之后，发现可以端到端来实现OCR，他是基于mxnet的，于是我想把它转到tensorflow这个框架来，顺便还能熟悉一下这个框架。本文主要介绍实现思路，更加细节的实现方法见另一篇。 正文生成数据利用captcha来生成验证码，具体生成验证码的代码请见这里，共生成4-6位包含数字和英文大小写的训练图片128000张和测试图片400张。命名规则就是num_label.png，生成的图片如下图 关于生成数据，再多说一点，可以像Xlvector那样一边生成一边训练，这样样本是无穷的，效果更好。但是实际应用中有限样本的情况还是更多的。 载入数据三种载入数据方式 在线生成调用keras的GeneratorEnqueuer，多线程在线生成，用了旷视的代码。详细代码见Github: gen.py 123456789101112131415161718192021222324def get_batch(num_workers, **kwargs): try: enqueuer = GeneratorEnqueuer(generator(**kwargs), use_multiprocessing=True) enqueuer.start(max_queue_size=24, workers=num_workers) generator_output = None while True: while enqueuer.is_running(): if not enqueuer.queue.empty(): generator_output = enqueuer.queue.get() break else: time.sleep(0.01) yield generator_output generator_output = None finally: if enqueuer is not None: enqueuer.stop()if __name__ == &#x27;__main__&#x27;: # gen = generator(batch_size=32, vis=False) gen = get_batch(num_workers=24,batch_size=32,vis=False) while True: images, labels,label_len,time_step = next(gen) print(len(images),&quot; &quot;,images[0].shape) pipeline最开始想通过一个tf.train.string_input_producer来读入所有的文件名，然后以pipline的方式读入，但是由于标签的是不定长的，想通过正则来生成label，一开始是想用py_func来实现，后来发现传入string会有问题，所以最后还是选择生成tf.record文件，关于不定长问题，把比较短的标签在后面补零（0是blank的便签，就是说自己的类别中不能出现0这个类），然后读出每个batch后，再把0去掉。 一次性载入我这里给一个目录，然后遍历里面所有的文件，等到训练的时候，每一个epoch循环把文件的index给手动shuffle一下，然后就可以每次截取出一个batch来用作输入了 123456789101112131415161718192021222324252627282930313233343536373839class DataIterator: def __init__(self, data_dir): self.image_names = [] self.image = [] self.labels=[] for root, sub_folder, file_list in os.walk(data_dir): for file_path in file_list: image_name = os.path.join(root,file_path) self.image_names.append(image_name) im = cv2.imread(image_name,0).astype(np.float32)/255. im = cv2.resize(im,(image_width,image_height)) # transpose to (160*60) and the step shall be 160 # in this way, each row is a feature vector im = im.swapaxes(0,1) self.image.append(np.array(im)) #image is named as ./&lt;folder&gt;/00000_abcd.png code = image_name.split(&#x27;/&#x27;)[2].split(&#x27;_&#x27;)[1].split(&#x27;.&#x27;)[0] code = [SPACE_INDEX if code == SPACE_TOKEN else maps[c] for c in list(code)] self.labels.append(code) print(image_name,&#x27; &#x27;,code) @property def size(self): return len(self.labels) def input_index_generate_batch(self,index=None): if index: image_batch=[self.image[i] for i in index] label_batch=[self.labels[i] for i in index] else: # get the whole data as input image_batch=self.image label_batch=self.labels def get_input_lens(sequences): lengths = np.asarray([len(s) for s in sequences], dtype=np.int64) return sequences,lengths batch_inputs,batch_seq_len = get_input_lens(np.array(image_batch)) batch_labels = sparse_tuple_from_label(label_batch) return batch_inputs,batch_seq_len,batch_labels 需要注意的是tensorflow lstm输入格式的问题，其label tensor应该是稀疏矩阵，所以读取图片和label之后，还要进行一些处理，具体可以看代码关于载入图片，发现12.8w张图一次读进内存，内存也就涨了5G，如果训练数据加大，还是加一个pipeline来读比较好。 网络结构然后是网络结构 1234567891011121314151617181920212223242526272829303132333435363738graph = tf.Graph()with graph.as_default(): inputs = tf.placeholder(tf.float32, [None, None, num_features]) labels = tf.sparse_placeholder(tf.int32) seq_len = tf.placeholder(tf.int32, [None]) # Stacking rnn cells stack = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.LSTMCell(FLAGS.num_hidden,state_is_tuple=True) for i in range(FLAGS.num_layers)] , state_is_tuple=True) # The second output is the last state and we will no use that outputs, _ = tf.nn.dynamic_rnn(stack, inputs, seq_len, dtype=tf.float32) shape = tf.shape(inputs) batch_s, max_timesteps = shape[0], shape[1] # Reshaping to apply the same weights over the timesteps outputs = tf.reshape(outputs, [-1, FLAGS.num_hidden]) # Truncated normal with mean 0 and stdev=0.1 W = tf.Variable(tf.truncated_normal([FLAGS.num_hidden, num_classes], stddev=0.1),name=&#x27;W&#x27;) b = tf.Variable(tf.constant(0., shape=[num_classes],name=&#x27;b&#x27;)) # Doing the affine projection logits = tf.matmul(outputs, W) + b # Reshaping back to the original shape logits = tf.reshape(logits, [batch_s, -1, num_classes]) # Time major logits = tf.transpose(logits, (1, 0, 2)) global_step = tf.Variable(0,trainable=False) loss = tf.nn.ctc_loss(labels=labels,inputs=logits, sequence_length=seq_len) cost = tf.reduce_mean(loss) #optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, # momentum=FLAGS.momentum).minimize(cost,global_step=global_step) optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.initial_learning_rate, beta1=FLAGS.beta1,beta2=FLAGS.beta2).minimize(loss,global_step=global_step) # Option 2: tf.contrib.ctc.ctc_beam_search_decoder # (it&#x27;s slower but you&#x27;ll get better results) #decoded, log_prob = tf.nn.ctc_greedy_decoder(logits, seq_len,merge_repeated=False) decoded, log_prob = tf.nn.ctc_beam_search_decoder(logits, seq_len,merge_repeated=False) # Inaccuracy: label error rate lerr = tf.reduce_mean(tf.edit_distance(tf.cast(decoded[0], tf.int32), labels)) 这里我参考了stackoverflow的一篇帖子写的，根据tensorflow 1.0.1的版本做了微调，使用了Adam作为optimizer。需要注意的是ctc_beam_search_decoder是非常耗时的，见下图和greedy_decoder的区别是，greedy_decoder根据当前序列预测下一个字符，并且取概率最高的作为结果，再此基础上再进行下一次预测。而beam_search_decoder每次会保存取k个概率最高的结果，以此为基础再进行预测，并将下一个字符出现的概率与当前k个出现的概率相乘，这样就可以减缓贪心造成的丢失好解的情况，当k=1的时候，二者就一样了。 结果—update—在线生成毫无疑问因为样本量无穷，正确率最高，2w步时准确率超96%，继续训练，超98%. 把网络用在识别身份证号，试了73张网上爬的（不同分辨率下的）真实图片，错了一张，准确率在98%左右（不过毕竟身份证号比较简单） 大概14个epoch后，准确率过了50%，现在跑到了73%的正确率。最后，代码托管在Github上。 后记百度出了一个warpCTC可以加速CTC的计算，试用了一下CPU的版本发现好像没什么速度的提升，不知道是不是姿势不对，回头再试试GPU的版本。对于更加细节的实现方法（输入输出的构造，以及warpCTC和内置ctc_loss的异同）放在了另一篇博客。 warpCTC的GPU版本试过之后发现速度差不多,但是能极大的减少CPU的占用 对于不同的优化器，数据，同样的参数是不能普适的。往往之前的参数可以收敛，换个optimizer，数据，网络就不能收敛了。这个时候要微调参数。对于不同的优化器之间区别，文末有一篇神文可以参考 如果有发现问题，请前辈们一定要不吝赐教，在下方留言指出，或者在github上提出issue 参考链接不同Optimizer详解端到端的OCR：LSTM+CTC的实现Using Tensorflow’s Connectionist Temporal Classification (CTC) implementationctc_beam_search:","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"深度学习","slug":"技术杂谈/深度学习","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"ctc","slug":"ctc","permalink":"http://ilovin.me/tags/ctc/"},{"name":"lstm","slug":"lstm","permalink":"http://ilovin.me/tags/lstm/"}]},{"title":"/usr/bin/ccache invalid option -- 'E'的解决方法","slug":"ccache-error","date":"un55fin55","updated":"un11fin11","comments":true,"path":"2017-03-17/ccache-error/","link":"","permalink":"http://ilovin.me/2017-03-17/ccache-error/","excerpt":"前言更新：今天在编译Opencv，开启CUDA选项的时候也出现了这个错误，解决方法是需要指定CUDA的编译器。在试图安装warp-ctc的时候，报错/usr/bin/ccache: invalid option -- &#39;E&#39;，执行了ccache –help,发现并没有-E这个选项，网上查了一下，发现一篇文章,上面说可能是cmake的问题，我发现自己的版本是3.2.2的，于是升级了一下cmake，把build清空后，重新编译就好了 具体实现编译OpenCV的时候指定g++cmake -D CUDA_HOST_COMPILER=/usr/local/bin/g++ ..","text":"前言更新：今天在编译Opencv，开启CUDA选项的时候也出现了这个错误，解决方法是需要指定CUDA的编译器。在试图安装warp-ctc的时候，报错/usr/bin/ccache: invalid option -- &#39;E&#39;，执行了ccache –help,发现并没有-E这个选项，网上查了一下，发现一篇文章,上面说可能是cmake的问题，我发现自己的版本是3.2.2的，于是升级了一下cmake，把build清空后，重新编译就好了 具体实现编译OpenCV的时候指定g++cmake -D CUDA_HOST_COMPILER=/usr/local/bin/g++ .. 升级cmake，下载最新版本建议下到/opt/中，因为待会安装的时候cmake会默认安装到你执行安装的目录 1234sudo apt-get remove cmakechmod +x ./cmake-***.shsudo ./cmake-***.shsudo ln -sf /opt/cmake-***/bin/* /usr/local/bin","categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"linux","slug":"技术杂谈/linux","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/linux/"},{"name":"error","slug":"技术杂谈/linux/error","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/linux/error/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://ilovin.me/tags/linux/"},{"name":"ctc","slug":"ctc","permalink":"http://ilovin.me/tags/ctc/"}]},{"title":"Hexo+Next搜索框自动定位获得焦点","slug":"hexo-search","date":"un44fin44","updated":"un00fin00","comments":true,"path":"2017-03-16/hexo-search/","link":"","permalink":"http://ilovin.me/2017-03-16/hexo-search/","excerpt":"Next默认的本地搜索，在点击一次搜索后会弹出一个页面。这个时候还需要再点击一次搜索框，才能进行搜索，这样很不方便。如下所示，只需要添加一小段代码就可以实现自动捕获焦点，减少重复劳动","text":"Next默认的本地搜索，在点击一次搜索后会弹出一个页面。这个时候还需要再点击一次搜索框，才能进行搜索，这样很不方便。如下所示，只需要添加一小段代码就可以实现自动捕获焦点，减少重复劳动 修改\\themes\\next\\layout\\_scripts\\third-party\\local_search.swig 自动捕获焦点的一点修改需要在两个地方，添加一小段代码 123456789101112&#125;).get();//添加这部分，加载xml后，再去取焦点setTimeout( function()&#123;try&#123;var t = document.getElementById(&#x27;local-search-input&#x27;);t.focus();t.select();&#125; catch(e)&#123;&#125;&#125;, 10);//endvar $input = document.getElementById(search_id);var $resultContent = document.getElementById(content_id); 1234567891011121314// handle and trigger popup window;// 在这下面找到&#125; else &#123; proceedsearch(); //添加下面这部分 setTimeout( function()&#123; try&#123; var t = document.getElementById(&#x27;local-search-input&#x27;); t.focus(); t.select(); &#125; catch(e)&#123;&#125; &#125;, 10); //end&#125;; 然后就可以实现自动定位了。 添加自动捕获焦点功能这段是历史代码，请使用上面的代码，效果更佳 1234567891011// handle and trigger popup window;$(&#x27;.popup-trigger&#x27;).click(function(e) &#123; e.stopPropagation();//添加如下代码， setTimeout( function()&#123; try&#123; var t = document.getElementById(&#x27;local-search-input&#x27;); t.focus(); t.select(); &#125; catch(e)&#123;&#125; &#125;, 250); 上面这段代码有一点问题，就是当第一次加载网页的时候，那个时候local search的xml文件还没有加载，这个时候代码是不能执行成功的。","categories":[{"name":"hexo","slug":"hexo","permalink":"http://ilovin.me/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://ilovin.me/tags/hexo/"}]},{"title":"Hexo博客的搭建与Next主题修改","slug":"hexo-setup","date":"un33fin33","updated":"un00fin00","comments":true,"path":"2017-03-15/hexo-setup/","link":"","permalink":"http://ilovin.me/2017-03-15/hexo-setup/","excerpt":"Hexo 博客的搭建这篇文章介绍了Hexo的搭建，以及Next主题的使用和一些实用的更改主题方法。参考了网上的另一篇文章以及官方文档,把所有模块都列出来了，哪里不会点哪里","text":"Hexo 博客的搭建这篇文章介绍了Hexo的搭建，以及Next主题的使用和一些实用的更改主题方法。参考了网上的另一篇文章以及官方文档,把所有模块都列出来了，哪里不会点哪里 Hexo 博客的搭建 准备工作与参考链接 安装Hexo 如何使用Hexo - Hello World 部署到Git 使用Next主题与各种第三方服务 添加tags与categories 第三方服务 多说评论 Disqus评论 百度统计 阅读次数统计 搜索 站内搜索 主题优化 自动定位搜索框的焦点 更改颜色与主题 背景动画 设置首页不显示全文（而是阅读更多） 准备工作与参考链接 nodejs 与npm的安装，windows下安装时默认勾选npm 注意 - 如果npm install的时候连接不上那么可以通过npm config set proxy http://ip:port 来设置代理 theme-next 需要更改theme为next的时候，参考此链接修改安装Hexo 安装Hexo1234mkdir hexo #创建一个文件夹cd hexonpm install -g hexo-clinpm install hexo --save 初始化一个hexo目录 hexo init如果想清除该目录则hexo clean 安装Hexo 插件：自动生成sitemap,Rss，部署到git等，建议安装12345678910111213npm install hexo-generator-index --savenpm install hexo-generator-archive --savenpm install hexo-generator-category --savenpm install hexo-generator-tag --savenpm install hexo-server --savenpm install hexo-deployer-git --savenpm install hexo-deployer-heroku --savenpm install hexo-deployer-rsync --savenpm install hexo-deployer-openshift --savenpm install hexo-renderer-marked@0.2 --savenpm install hexo-renderer-stylus@0.2 --savenpm install hexo-generator-feed@1 --savenpm install hexo-generator-sitemap@1 --save 如何使用Hexo - Hello World只需要四步 Create a new post默认使用post，关于模版在scaffolds文件夹下,可以更改模版，比如添加categorises: 以添加分类 $ hexo new “My New Post”More info: Writing Run server可以在本地预览你对博客所做的更改http://127.0.0.1:4000 $ hexo serverMore info: Server Generate static files生成静态文件 $ hexo generateMore info: Generating Deploy to remote sites需要提前配置好要发布到的网站 $ hexo deployMore info: Deployment 部署到Git配置全局_config.yml修改内容 1234deploy: type: git repository: git@github.com:&#123;yourGitName&#125;/&#123;yourGitName&#125;.github.io.git branch: master 然后就可以通过hexo deploy来发布了，注意需要配置好github上的ssh密钥(yue) 使用Next主题与各种第三方服务参考这个链接进行配置修改，很快就可以完成。注意theme主题也有一个_config.yml配置文件，不要弄混了然后修改全局_config.yml中的theme: next 就可以了 添加tags与categories可以让博客拥有标签和目录的功能，注意目录功能是有一级一级的先后顺序的。而tag是没有顺序的运行下面两条命令,会自动生成相应目录,在目录下会有index.mdhexo new page tagshexo new page categories并且修改相应sources文件下各目录内的index.md 12type: &quot;tags&quot; #或type: “categories&quot;comments: false 其中comments:false 的意思是关闭评论功能最后在主题_config.yml下的Menu Settings部分，将相应的tags和categories目录配置好即可 第三方服务多说评论今天收到邮件，多说要在6.1关闭服务了…在多说建立一个站点，选择我要安装，然后把多说域名拷贝下来填写到主题配置文件中 duoshuo_shortname: 你的多说域名 Disqus评论由于多说的服务马上就要停了，所以要换一套服务，备选的方案有网易云跟帖,畅言,来必力，以及disqus。简单说一下区别，试用了网易云跟帖，发现github.io的域名已经不能注册了，畅言需要备案，而且还有盖章的功能，显得太乱，不适合个人博客，另外评论是要被监管的。来必力界面看起来还不错，但是免费版不支持微信，豆瓣等的登录，并且博客访问量大于1500之后，可能会有广告，尤其是试用了一下，发现加载很慢，想来想去还不如用disqus，反正都是不支持国内sns登录的去disqus注册个账号，然后建一个站，会给你一个站点名，随后将这个名字，填写到 disqus_shortname: your_name 最后还可以在disqus设置允许以游客发身份回帖，这样防止被墙的无法登录不存在网站的问题。另外游客的回复是需要管理员approve之后才能正常显示的。另外需要注意，网站需要开启https访问才可以加载disqus模块，具体代码在这里 百度统计需要注册一个账号，并且打开代码统计部分hm.src = &quot;https://hm.baidu.com/hm.js? 复制问号后面的一段字编辑到主题配置文件中 baidu_analytics: 那串字符 阅读次数统计参见这篇文章进行配置需要注册LeanCloud的账号 搜索站内搜索npm i -S hexo-generator-json-content并且在主题配置文档中设置 local_search truegithub链接 主题优化自动定位搜索框的焦点见我写的另一篇文章 更改颜色与主题 自定义页面显示方式在next\\source\\css\\_custom\\custom.styl中更改比如说更改超链的颜色为蓝色，参考了这篇文章，代码如下12345678.post-body p a &#123;color: #0593d3;border-bottom: none;&amp;:hover &#123; color: #0477ab; text-decoration: underline;&#125;&#125; 更改字体颜色在\\themes\\next\\source\\css\\_variables 更改base.styl.比如想更改选中字体的颜色，就可以更改selection-bg 更改或添加主题在\\themes\\next\\source\\css\\_common\\components\\highlight中更改theme.styl 背景动画- 将 [particle.js](https://github.com/ilovin/ilovin.github.io/blob/master/js/src/particle.js) 文件添加到 `\\themes\\next\\source\\js\\src` 文件目录下 - `\\themes\\next\\layout\\_layout.swg`，在`&lt;/body&gt;`前添加 12&lt;!-- 背景动画 --&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/particle.js&quot;&gt;&lt;/script&gt; 设置首页不显示全文（而是阅读更多）在主题_config.yml中如下所示，改成True 123auto_excerpt:enable: Truelength: 150 更美观一些的方式是在文章自己认为合适的位置添加&lt;!-- more --&gt;","categories":[{"name":"hexo","slug":"hexo","permalink":"http://ilovin.me/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://ilovin.me/tags/hexo/"}]},{"title":"test","slug":"test","date":"un33fin33","updated":"un55fin55","comments":true,"path":"2017-03-15/test/","link":"","permalink":"http://ilovin.me/2017-03-15/test/","excerpt":"这个一个测试文档","text":"这个一个测试文档 这篇博客是根据这篇文章生成注意：tags 和 categories 需要生成index.md之后才可以点击在首页插图只需要在title下一行添加 1photos: http:&#x2F;&#x2F;bruce.u.qiniudn.com&#x2F;2013&#x2F;11&#x2F;27&#x2F;reading&#x2F;photos-1.jpg","categories":[{"name":"test","slug":"test","permalink":"http://ilovin.me/categories/test/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://ilovin.me/tags/hexo/"}]}],"categories":[{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"深度学习","slug":"技术杂谈/深度学习","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"Reading List","slug":"Reading-List","permalink":"http://ilovin.me/categories/Reading-List/"},{"name":"python","slug":"技术杂谈/python","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/python/"},{"name":"hexo","slug":"hexo","permalink":"http://ilovin.me/categories/hexo/"},{"name":"linux","slug":"技术杂谈/linux","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/linux/"},{"name":"error","slug":"技术杂谈/linux/error","permalink":"http://ilovin.me/categories/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/linux/error/"},{"name":"test","slug":"test","permalink":"http://ilovin.me/categories/test/"}],"tags":[{"name":"杂谈","slug":"杂谈","permalink":"http://ilovin.me/tags/%E6%9D%82%E8%B0%88/"},{"name":"行业","slug":"行业","permalink":"http://ilovin.me/tags/%E8%A1%8C%E4%B8%9A/"},{"name":"megvii/face++","slug":"megvii-face","permalink":"http://ilovin.me/tags/megvii-face/"},{"name":"深度学习","slug":"深度学习","permalink":"http://ilovin.me/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"指纹/fingerprint","slug":"指纹-fingerprint","permalink":"http://ilovin.me/tags/%E6%8C%87%E7%BA%B9-fingerprint/"},{"name":"技术杂谈","slug":"技术杂谈","permalink":"http://ilovin.me/tags/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://ilovin.me/tags/ubuntu/"},{"name":"install","slug":"install","permalink":"http://ilovin.me/tags/install/"},{"name":"beam_search","slug":"beam-search","permalink":"http://ilovin.me/tags/beam-search/"},{"name":"attentiaon","slug":"attentiaon","permalink":"http://ilovin.me/tags/attentiaon/"},{"name":"ctc","slug":"ctc","permalink":"http://ilovin.me/tags/ctc/"},{"name":"lstm","slug":"lstm","permalink":"http://ilovin.me/tags/lstm/"},{"name":"python","slug":"python","permalink":"http://ilovin.me/tags/python/"},{"name":"hexo","slug":"hexo","permalink":"http://ilovin.me/tags/hexo/"},{"name":"linux","slug":"linux","permalink":"http://ilovin.me/tags/linux/"}]}